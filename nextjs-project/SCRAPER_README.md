# Web Scraper ç³»ç»Ÿå®Œæ•´è¯´æ˜ ğŸ•·ï¸

ä¸€ä¸ªä¼ä¸šçº§çš„ç½‘ç»œçˆ¬è™«ç³»ç»Ÿï¼Œç”¨äºä»æƒå¨å¥åº·ç½‘ç«™ï¼ˆCDCã€AAPã€WHOç­‰ï¼‰è‡ªåŠ¨çˆ¬å–å†…å®¹å¹¶å­˜å‚¨åˆ°Supabaseã€‚

## ğŸ“š æ–‡æ¡£ç´¢å¼•

1. **[SCRAPER_QUICKSTART.md](./SCRAPER_QUICKSTART.md)** - 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹æŒ‡å—
2. **[SCRAPER_GUIDE.md](./SCRAPER_GUIDE.md)** - å®Œæ•´ä½¿ç”¨æ–‡æ¡£
3. æœ¬æ–‡æ¡£ - ç³»ç»Ÿæ¶æ„å’ŒæŠ€æœ¯ç»†èŠ‚

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     å¤–éƒ¨è§¦å‘å™¨                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚GitHub    â”‚  â”‚Vercel    â”‚  â”‚External  â”‚  â”‚Manual    â”‚   â”‚
â”‚  â”‚Actions   â”‚  â”‚Cron      â”‚  â”‚Cron      â”‚  â”‚Trigger   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         API Layer (Next.js)             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚  POST /api/scraper/run           â”‚  â”‚
        â”‚  â”‚  - è¿è¡Œçˆ¬è™«ä»»åŠ¡                   â”‚  â”‚
        â”‚  â”‚  - è¿”å›æ‰§è¡Œç»“æœ                   â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚  GET /api/scraper/status         â”‚  â”‚
        â”‚  â”‚  - æŸ¥è¯¢çˆ¬å–çŠ¶æ€                   â”‚  â”‚
        â”‚  â”‚  - è¿”å›ç»Ÿè®¡ä¿¡æ¯                   â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Core Scraper Engine               â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ web-scraper.js                   â”‚  â”‚
        â”‚  â”‚ - HTTPè¯·æ±‚ç®¡ç†                    â”‚  â”‚
        â”‚  â”‚ - å†…å®¹æå–                        â”‚  â”‚
        â”‚  â”‚ - æ•°æ®æ¸…æ´—                        â”‚  â”‚
        â”‚  â”‚ - é”™è¯¯é‡è¯•                        â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ scraper-config.js                â”‚  â”‚
        â”‚  â”‚ - æ•°æ®æºé…ç½®                      â”‚  â”‚
        â”‚  â”‚ - CSSé€‰æ‹©å™¨                       â”‚  â”‚
        â”‚  â”‚ - æ•°æ®æ˜ å°„è§„åˆ™                    â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Data Processing                â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ å†…å®¹éªŒè¯                          â”‚  â”‚
        â”‚  â”‚ - é•¿åº¦æ£€æŸ¥                        â”‚  â”‚
        â”‚  â”‚ - è´¨é‡è¯„åˆ†                        â”‚  â”‚
        â”‚  â”‚ - å»é‡æ£€æµ‹                        â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ æ•°æ®è½¬æ¢                          â”‚  â”‚
        â”‚  â”‚ - HTML â†’ Markdown                â”‚  â”‚
        â”‚  â”‚ - æå–å…³é”®ä¿¡æ¯                    â”‚  â”‚
        â”‚  â”‚ - ç”Ÿæˆå…ƒæ•°æ®                      â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         Storage Layer                  â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚ Supabase     â”‚  â”‚ Local Files  â”‚   â”‚
        â”‚  â”‚ - articles   â”‚  â”‚ - Raw data   â”‚   â”‚
        â”‚  â”‚ - kb_sources â”‚  â”‚ - Backups    â”‚   â”‚
        â”‚  â”‚ - citations  â”‚  â”‚ - Cache      â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ æ–‡ä»¶ç»“æ„

```
nextjs-project/
â”œâ”€â”€ scripts/                        # çˆ¬è™«è„šæœ¬
â”‚   â”œâ”€â”€ web-scraper.js             # æ ¸å¿ƒçˆ¬è™«å¼•æ“ â­
â”‚   â”œâ”€â”€ scraper-config.js          # é…ç½®æ–‡ä»¶ â­
â”‚   â”œâ”€â”€ review-scraped-content.js  # å†…å®¹å®¡æ ¸å·¥å…·
â”‚   â”œâ”€â”€ scraper-stats.js           # ç»Ÿè®¡åˆ†æ
â”‚   â”œâ”€â”€ cron-example.js            # Cronç¤ºä¾‹
â”‚   â””â”€â”€ test-scraper-api.sh        # APIæµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ src/app/api/scraper/           # APIè·¯ç”±
â”‚   â”œâ”€â”€ run/route.ts               # è¿è¡Œçˆ¬è™« â­
â”‚   â””â”€â”€ status/route.ts            # æŸ¥è¯¢çŠ¶æ€ â­
â”‚
â”œâ”€â”€ data/                          # æ•°æ®ç›®å½•
â”‚   â””â”€â”€ scraped/                   # çˆ¬å–çš„åŸå§‹æ•°æ®
â”‚
â”œâ”€â”€ cache/                         # ç¼“å­˜ç›®å½•
â”‚   â””â”€â”€ scraper/                   # çˆ¬è™«ç¼“å­˜
â”‚
â”œâ”€â”€ reports/                       # æŠ¥å‘Šç›®å½•
â”‚   â””â”€â”€ scraper-stats.json         # ç»Ÿè®¡æŠ¥å‘Š
â”‚
â”œâ”€â”€ .github/workflows/             # GitHub Actions
â”‚   â””â”€â”€ scraper-cron.yml           # å®šæ—¶ä»»åŠ¡é…ç½® â­
â”‚
â”œâ”€â”€ SCRAPER_README.md              # æœ¬æ–‡æ¡£
â”œâ”€â”€ SCRAPER_GUIDE.md               # ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ SCRAPER_QUICKSTART.md          # å¿«é€Ÿå¼€å§‹
â””â”€â”€ vercel-cron-example.json       # Vercelé…ç½®ç¤ºä¾‹
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. Web Scraper (`web-scraper.js`)

**åŠŸèƒ½ï¼š**
- HTTPè¯·æ±‚ç®¡ç†ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
- HTMLå†…å®¹æå–ï¼ˆä½¿ç”¨Cheerioï¼‰
- æ•°æ®æ¸…æ´—å’ŒéªŒè¯
- å¹¶å‘æ§åˆ¶
- é”™è¯¯å¤„ç†

**å…³é”®æ–¹æ³•ï¼š**
```javascript
fetchWithRetry(url, retries)      // å¸¦é‡è¯•çš„HTTPè¯·æ±‚
extractContent(html, selectors)   // æå–é¡µé¢å†…å®¹
validateContent(content)          // éªŒè¯å†…å®¹è´¨é‡
scrapePage(source, page)          // çˆ¬å–å•ä¸ªé¡µé¢
scrapeAllSources()                // çˆ¬å–æ‰€æœ‰æ¥æº
```

### 2. Scraper Config (`scraper-config.js`)

**åŠŸèƒ½ï¼š**
- å®šä¹‰æ•°æ®æ¥æº
- é…ç½®CSSé€‰æ‹©å™¨
- è®¾ç½®æ•°æ®æ˜ å°„è§„åˆ™
- é…ç½®çˆ¬å–å‚æ•°

**å¯é…ç½®é¡¹ï¼š**
- `SOURCES` - æ•°æ®æ¥æºåˆ—è¡¨
- `CLEANING_RULES` - æ¸…æ´—è§„åˆ™
- `SCRAPER_CONFIG` - è¿è¡Œé…ç½®
- `DATA_MAPPING` - æ•°æ®æ˜ å°„

### 3. API Routes

**`/api/scraper/run`**
- æ–¹æ³•ï¼šPOST, GET
- åŠŸèƒ½ï¼šè¿è¡Œçˆ¬è™«ã€æŸ¥è¯¢é…ç½®
- è®¤è¯ï¼šBearer Token

**`/api/scraper/status`**
- æ–¹æ³•ï¼šGET
- åŠŸèƒ½ï¼šæŸ¥è¯¢çˆ¬å–çŠ¶æ€
- è¿”å›ï¼šæœ€è¿‘æ–‡ç« ã€ç»Ÿè®¡ä¿¡æ¯

### 4. å®¡æ ¸å·¥å…· (`review-scraped-content.js`)

**åŠŸèƒ½ï¼š**
- äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢
- æŸ¥çœ‹å¾…å®¡æ ¸æ–‡ç« 
- æ‰¹é‡/å•ä¸ªæ“ä½œ
- å‘å¸ƒ/åˆ é™¤/ç¼–è¾‘

### 5. ç»Ÿè®¡åˆ†æ (`scraper-stats.js`)

**åŠŸèƒ½ï¼š**
- ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
- å†…å®¹è´¨é‡åˆ†æ
- æ¥æºåˆ†å¸ƒç»Ÿè®¡
- æœ¬åœ°æ–‡ä»¶åˆ†æ

---

## ğŸ” å®‰å…¨æœºåˆ¶

### 1. APIè®¤è¯

```typescript
// Bearer Tokenè®¤è¯
Authorization: Bearer YOUR_API_KEY
```

### 2. ç¯å¢ƒå˜é‡ä¿æŠ¤

```bash
# .env.local (ä¸ä¼šæäº¤åˆ°Git)
SCRAPER_API_KEY=your_secure_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_key
```

### 3. å†…å®¹éªŒè¯

- é•¿åº¦é™åˆ¶ï¼ˆ100-50000å­—ç¬¦ï¼‰
- æ ‡é¢˜å¿…éœ€
- æœ€å°‘æ®µè½æ•°
- æ¥æºéªŒè¯

### 4. æ•°æ®éš”ç¦»

- çˆ¬å–å†…å®¹é»˜è®¤çŠ¶æ€ï¼š`draft`
- éœ€è¦äººå·¥å®¡æ ¸æ‰èƒ½å‘å¸ƒ
- è¿½è¸ªæ¥æºï¼ˆ`reviewed_by: 'Web Scraper Bot'`ï¼‰

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. å¹¶å‘æ§åˆ¶

```javascript
concurrency: {
  maxConcurrent: 2,           // æœ€å¤š2ä¸ªå¹¶å‘è¯·æ±‚
  delayBetweenRequests: 1000  // è¯·æ±‚é—´éš”1ç§’
}
```

### 2. é‡è¯•æœºåˆ¶

```javascript
retryConfig: {
  maxRetries: 3,
  retryDelay: 2000,
  backoffMultiplier: 2  // æŒ‡æ•°é€€é¿
}
```

### 3. ç¼“å­˜ç­–ç•¥

```javascript
cache: {
  enabled: true,
  ttl: 86400000,  // 24å°æ—¶
  directory: './cache/scraper'
}
```

### 4. å»é‡æ£€æµ‹

- ä½¿ç”¨`slug`ä½œä¸ºå”¯ä¸€æ ‡è¯†
- æ•°æ®åº“å±‚é¢çš„å”¯ä¸€çº¦æŸ
- æ’å…¥å‰æ£€æŸ¥æ˜¯å¦å­˜åœ¨

---

## ğŸ“Š æ•°æ®æµç¨‹

### 1. çˆ¬å–é˜¶æ®µ

```
æƒå¨ç½‘ç«™ â†’ HTTPè¯·æ±‚ â†’ HTMLå“åº” â†’ Cheerioè§£æ
```

### 2. å¤„ç†é˜¶æ®µ

```
åŸå§‹HTML â†’ æ¸…ç†æ ‡ç­¾ â†’ æå–å†…å®¹ â†’ éªŒè¯è´¨é‡
```

### 3. è½¬æ¢é˜¶æ®µ

```
ç»“æ„åŒ–æ•°æ® â†’ æ•°æ®æ˜ å°„ â†’ ç”Ÿæˆå…ƒæ•°æ® â†’ æ ¼å¼è½¬æ¢
```

### 4. å­˜å‚¨é˜¶æ®µ

```
â”Œâ”€ æœ¬åœ°æ–‡ä»¶ï¼ˆåŸå§‹æ•°æ®ï¼‰
â””â”€ Supabaseæ•°æ®åº“
   â”œâ”€ kb_sourcesï¼ˆæ¥æºï¼‰
   â”œâ”€ articlesï¼ˆæ–‡ç« ï¼ŒdraftçŠ¶æ€ï¼‰
   â””â”€ citationsï¼ˆå¼•ç”¨ï¼‰
```

---

## ğŸ¯ æ•°æ®æ¥æº

### å½“å‰æ”¯æŒçš„æƒå¨æ¥æº

| æ¥æº | ç»„ç»‡ | ç­‰çº§ | ç±»å‹ | é¡µé¢æ•° |
|------|------|------|------|--------|
| CDC | Centers for Disease Control | A | æ”¿åºœæœºæ„ | 2 |
| AAP | American Academy of Pediatrics | A | ä¸“ä¸šåä¼š | 2 |
| Health Canada | Health Canada | A | æ”¿åºœæœºæ„ | 1 |
| WHO | World Health Organization | A | å›½é™…ç»„ç»‡ | 1 |
| NIH | National Institutes of Health | A | æ”¿åºœæœºæ„ | 1 |
| Mayo Clinic | Mayo Clinic | A | åŒ»ç–—æœºæ„ | 1 |

**æ€»è®¡ï¼š** 6ä¸ªæ¥æºï¼Œ8ä¸ªé¡µé¢

### æ·»åŠ æ–°æ¥æº

åœ¨ `scraper-config.js` ä¸­æ·»åŠ ï¼š

```javascript
NEW_SOURCE: {
  id: 'unique-id',
  name: 'Source Name',
  organization: 'Org Name',
  baseUrl: 'https://example.com',
  grade: 'A',  // A, B, C, D
  targetPages: [
    {
      url: 'https://example.com/page',
      type: 'content-type',
      category: 'category',
      selectors: {
        title: 'h1',
        content: '.content',
        paragraphs: 'p',
        lists: 'ul, ol'
      }
    }
  ]
}
```

---

## ğŸ”„ Cron Jobé…ç½®

### é€‰é¡¹1: GitHub Actionsï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹ï¼š**
- âœ… å®Œå…¨å…è´¹
- âœ… å¯é ç¨³å®š
- âœ… å®Œæ•´æ—¥å¿—
- âœ… æ˜“äºè°ƒè¯•

**é…ç½®ï¼š**
```yaml
# .github/workflows/scraper-cron.yml
on:
  schedule:
    - cron: '0 2 * * *'  # æ¯å¤©å‡Œæ™¨2ç‚¹
```

### é€‰é¡¹2: Vercel Cron

**ä¼˜ç‚¹ï¼š**
- âœ… ä¸éƒ¨ç½²é›†æˆ
- âœ… é›¶é…ç½®
- âœ… è‡ªåŠ¨æ‰©å±•

**é™åˆ¶ï¼š**
- âš ï¸ Proè®¡åˆ’åŠŸèƒ½
- âš ï¸ éœ€è¦é…ç½®Header

**é…ç½®ï¼š**
```json
{
  "crons": [{
    "path": "/api/scraper/run",
    "schedule": "0 2 * * *"
  }]
}
```

### é€‰é¡¹3: å¤–éƒ¨CronæœåŠ¡

**æ¨èæœåŠ¡ï¼š**
- **EasyCron** - åŠŸèƒ½ä¸°å¯Œ
- **Cron-job.org** - å…è´¹å¯é 
- **UptimeRobot** - å…¼é¡¾ç›‘æ§

---

## ğŸ“ˆ ç›‘æ§å’Œç»´æŠ¤

### 1. æŸ¥çœ‹ç»Ÿè®¡

```bash
npm run scrape:stats          # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
npm run scrape:report         # ç”ŸæˆJSONæŠ¥å‘Š
```

### 2. å®¡æ ¸å†…å®¹

```bash
npm run scrape:review         # äº¤äº’å¼å®¡æ ¸å·¥å…·
```

### 3. æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹åŸå§‹æ•°æ®
ls -lh data/scraped/

# æŸ¥çœ‹æœ€æ–°æ–‡ä»¶
tail -f data/scraped/*.json
```

### 4. æ•°æ®åº“æŸ¥è¯¢

```sql
-- æŸ¥çœ‹å¾…å®¡æ ¸æ–‡ç« 
SELECT COUNT(*) FROM articles 
WHERE reviewed_by = 'Web Scraper Bot' 
AND status = 'draft';

-- æŸ¥çœ‹çˆ¬å–æ¥æº
SELECT * FROM kb_sources ORDER BY retrieved_at DESC;

-- æŸ¥çœ‹æœ€è¿‘çˆ¬å–çš„æ–‡ç« 
SELECT title, hub, created_at 
FROM articles 
WHERE reviewed_by = 'Web Scraper Bot' 
ORDER BY created_at DESC 
LIMIT 10;
```

---

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. 401 Unauthorized

**åŸå› ï¼š** APIå¯†é’¥é”™è¯¯

**è§£å†³ï¼š**
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $SCRAPER_API_KEY

# é‡æ–°ç”Ÿæˆå¯†é’¥
openssl rand -hex 32
```

#### 2. å†…å®¹æå–å¤±è´¥

**åŸå› ï¼š** CSSé€‰æ‹©å™¨è¿‡æ—¶

**è§£å†³ï¼š**
1. è®¿é—®ç›®æ ‡ç½‘ç«™æŸ¥çœ‹HTMLç»“æ„
2. ä½¿ç”¨æµè§ˆå™¨å¼€å‘å·¥å…·æ‰¾åˆ°æ­£ç¡®çš„é€‰æ‹©å™¨
3. æ›´æ–° `scraper-config.js`

#### 3. è¶…æ—¶é”™è¯¯

**åŸå› ï¼š** ç½‘ç»œæ…¢æˆ–ç½‘ç«™å“åº”æ…¢

**è§£å†³ï¼š**
```javascript
// å¢åŠ è¶…æ—¶æ—¶é—´
requestConfig: {
  timeout: 60000  // 60ç§’
}
```

#### 4. é‡å¤å†…å®¹

**åŸå› ï¼š** Slugç”Ÿæˆé€»è¾‘

**è§£å†³ï¼š**
- çˆ¬è™«ä¼šè‡ªåŠ¨è·³è¿‡é‡å¤çš„slug
- æ£€æŸ¥ `generateSlug()` å‡½æ•°é€»è¾‘
- æ‰‹åŠ¨æ¸…ç†é‡å¤æ•°æ®

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç¤¼è²Œçˆ¬å–

- âœ… è®¾ç½®åˆç†çš„è¯·æ±‚é—´éš”
- âœ… ä½¿ç”¨æœ‰æ„ä¹‰çš„User-Agent
- âœ… éµå®ˆrobots.txt
- âœ… é¿å…é«˜å¹¶å‘

### 2. å†…å®¹è´¨é‡

- âœ… æ‰€æœ‰å†…å®¹åˆå§‹ä¸ºdraft
- âœ… äººå·¥å®¡æ ¸åå†å‘å¸ƒ
- âœ… éªŒè¯å¼•ç”¨æ¥æº
- âœ… å®šæœŸæ›´æ–°

### 3. é”™è¯¯å¤„ç†

- âœ… è®°å½•æ‰€æœ‰é”™è¯¯
- âœ… ä¿å­˜åŸå§‹æ•°æ®
- âœ… è®¾ç½®é€šçŸ¥
- âœ… å®šæœŸæ£€æŸ¥æ—¥å¿—

### 4. æ•°æ®ç®¡ç†

- âœ… å®šæœŸå¤‡ä»½
- âœ… æ¸…ç†æ—§ç¼“å­˜
- âœ… å½’æ¡£è¿‡æœŸå†…å®¹
- âœ… ç›‘æ§å­˜å‚¨ç©ºé—´

---

## ğŸš€ å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# å®‰è£…
npm install

# æœ¬åœ°æµ‹è¯•
npm run scrape:test           # æµ‹è¯•å•é¡µ
npm run scrape                # å®Œæ•´çˆ¬å–

# APIæµ‹è¯•
npm run dev                   # å¯åŠ¨æœåŠ¡å™¨
./scripts/test-scraper-api.sh # æµ‹è¯•API

# å†…å®¹ç®¡ç†
npm run scrape:review         # å®¡æ ¸å†…å®¹
npm run scrape:stats          # æŸ¥çœ‹ç»Ÿè®¡
npm run scrape:report         # ç”ŸæˆæŠ¥å‘Š

# ç‰¹å®šæ¥æº
node scripts/web-scraper.js --sources CDC,AAP
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](./SCRAPER_QUICKSTART.md)
- [å®Œæ•´æŒ‡å—](./SCRAPER_GUIDE.md)

### æ—¥å¿—ä½ç½®

- çˆ¬å–æ•°æ®ï¼š`data/scraped/`
- ç»Ÿè®¡æŠ¥å‘Šï¼š`reports/scraper-stats.json`
- åº”ç”¨æ—¥å¿—ï¼šæ§åˆ¶å°è¾“å‡º

### æ£€æŸ¥æ¸…å•

- [ ] ç¯å¢ƒå˜é‡é…ç½®å®Œæˆ
- [ ] ä¾èµ–åŒ…å®‰è£…æˆåŠŸ
- [ ] æœ¬åœ°æµ‹è¯•é€šè¿‡
- [ ] APIæµ‹è¯•é€šè¿‡
- [ ] Cronä»»åŠ¡è®¾ç½®å®Œæˆ
- [ ] ç›‘æ§å’Œé€šçŸ¥é…ç½®
- [ ] æ–‡æ¡£é˜…è¯»å®Œæˆ

---

## ğŸ“„ è®¸å¯å’Œåˆè§„

### æ•°æ®ä½¿ç”¨

- éµå®ˆå„æ¥æºç½‘ç«™çš„ä½¿ç”¨æ¡æ¬¾
- ä»…ç”¨äºæ•™è‚²å’Œä¿¡æ¯ç›®çš„
- ä¿ç•™åŸå§‹æ¥æºå¼•ç”¨
- ä¸ç”¨äºå•†ä¸šç”¨é€”ï¼ˆæœªç»æˆæƒï¼‰

### å¼•ç”¨æ ¼å¼

æ‰€æœ‰çˆ¬å–çš„å†…å®¹éƒ½åŒ…å«ï¼š
- åŸå§‹æ¥æºé“¾æ¥
- å‡ºç‰ˆæ–¹åç§°
- æ£€ç´¢æ—¥æœŸ
- è®¸å¯ä¿¡æ¯

---

**åˆ›å»ºæ—¶é—´ï¼š** 2025-01-08  
**ç‰ˆæœ¬ï¼š** 1.0.0  
**ç»´æŠ¤è€…ï¼š** JupitLunar Team

**ğŸ‰ å¼€å§‹ä½¿ç”¨çˆ¬è™«ç³»ç»Ÿï¼**

