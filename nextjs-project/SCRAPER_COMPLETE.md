# âœ… çˆ¬è™«ç³»ç»Ÿå·²å®Œæˆï¼

æ­å–œï¼ä½ çš„Web Scraperç³»ç»Ÿå·²ç»å®Œå…¨é…ç½®å¥½äº†ã€‚

## ğŸ“¦ å·²åˆ›å»ºçš„æ–‡ä»¶

### æ ¸å¿ƒæ–‡ä»¶
- âœ… `scripts/web-scraper.js` - ä¸»çˆ¬è™«å¼•æ“
- âœ… `scripts/scraper-config.js` - é…ç½®æ–‡ä»¶
- âœ… `scripts/test-scraper-full.js` - å®Œæ•´æµ‹è¯•è„šæœ¬ â­
- âœ… `src/app/api/scraper/run/route.ts` - APIè·¯ç”±
- âœ… `src/app/api/scraper/status/route.ts` - çŠ¶æ€æŸ¥è¯¢API

### å·¥å…·è„šæœ¬
- âœ… `scripts/review-scraped-content.js` - å†…å®¹å®¡æ ¸å·¥å…·
- âœ… `scripts/scraper-stats.js` - ç»Ÿè®¡åˆ†æ
- âœ… `scripts/cron-example.js` - Cronç¤ºä¾‹
- âœ… `scripts/test-scraper-api.sh` - APIæµ‹è¯•è„šæœ¬

### è‡ªåŠ¨åŒ–é…ç½®
- âœ… `.github/workflows/scraper-cron.yml` - GitHub Actionså®šæ—¶ä»»åŠ¡

### æ–‡æ¡£
- âœ… `SCRAPER_README.md` - å®Œæ•´æŠ€æœ¯æ–‡æ¡£
- âœ… `SCRAPER_GUIDE.md` - ä½¿ç”¨æŒ‡å—
- âœ… `SCRAPER_QUICKSTART.md` - 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹
- âœ… `SCRAPER_COMPARISON.md` - Python vs Node.jså¯¹æ¯”
- âœ… `TEST_SCRAPER_NOW.md` - æµ‹è¯•è¯´æ˜ â­
- âœ… æœ¬æ–‡æ¡£ - å®Œæˆæ€»ç»“

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥ï¼‰

### ç¬¬1æ­¥ï¼šå®‰è£…ä¾èµ–
```bash
cd nextjs-project
npm install
```

### ç¬¬2æ­¥ï¼šé…ç½®ç¯å¢ƒå˜é‡
åœ¨ `.env.local` ä¸­æ·»åŠ ï¼š
```bash
# Supabaseï¼ˆåº”è¯¥å·²æœ‰ï¼‰
NEXT_PUBLIC_SUPABASE_URL=your_url
SUPABASE_SERVICE_ROLE_KEY=your_key

# çˆ¬è™«APIå¯†é’¥ï¼ˆæ–°å¢ï¼‰
SCRAPER_API_KEY=$(openssl rand -hex 32)
```

### ç¬¬3æ­¥ï¼šè¿è¡Œæµ‹è¯•
```bash
node scripts/test-scraper-full.js
```

## ğŸ“‹ å¯ç”¨å‘½ä»¤

### æµ‹è¯•å‘½ä»¤
```bash
# å¿«é€Ÿæµ‹è¯•ï¼ˆæ¨èï¼‰- çˆ¬å–2ä¸ªé¡µé¢
node scripts/test-scraper-full.js

# å•é¡µæµ‹è¯•
npm run scrape:test

# å®Œæ•´çˆ¬å–ï¼ˆæ‰€æœ‰é…ç½®çš„æ¥æºï¼‰
npm run scrape
```

### ç®¡ç†å‘½ä»¤
```bash
# å®¡æ ¸å†…å®¹
npm run scrape:review

# æŸ¥çœ‹ç»Ÿè®¡
npm run scrape:stats

# ç”ŸæˆæŠ¥å‘Š
npm run scrape:report
```

### APIå‘½ä»¤
```bash
# å¯åŠ¨æœåŠ¡å™¨
npm run dev

# æµ‹è¯•APIï¼ˆéœ€è¦å…ˆå¯åŠ¨æœåŠ¡å™¨ï¼‰
curl -X POST http://localhost:3000/api/scraper/run \
  -H "Authorization: Bearer YOUR_API_KEY"
```

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

### âœ… å·²å®ç°çš„åŠŸèƒ½

1. **ç½‘é¡µçˆ¬å–**
   - CDCï¼ˆç¾å›½ç–¾æ§ä¸­å¿ƒï¼‰
   - AAPï¼ˆç¾å›½å„¿ç§‘å­¦ä¼šï¼‰
   - Health Canada
   - WHOï¼ˆä¸–ç•Œå«ç”Ÿç»„ç»‡ï¼‰
   - NIHï¼ˆç¾å›½å›½ç«‹å«ç”Ÿç ”ç©¶é™¢ï¼‰
   - Mayo Clinic

2. **è‡ªåŠ¨å»é‡**
   - é€šè¿‡slugæ£€æŸ¥ï¼Œä¸ä¼šé‡å¤æ’å…¥
   - æ•°æ®åº“å”¯ä¸€çº¦æŸä¿æŠ¤

3. **æ•°æ®å­˜å‚¨**
   - articles è¡¨ï¼ˆæ–‡ç« å†…å®¹ï¼‰
   - kb_sources è¡¨ï¼ˆæ•°æ®æ¥æºï¼‰
   - citations è¡¨ï¼ˆå¼•ç”¨æ¥æºï¼‰

4. **APIæ¥å£**
   - POST /api/scraper/runï¼ˆè¿è¡Œçˆ¬è™«ï¼‰
   - GET /api/scraper/runï¼ˆæŸ¥è¯¢é…ç½®ï¼‰
   - GET /api/scraper/statusï¼ˆæŸ¥è¯¢çŠ¶æ€ï¼‰

5. **å†…å®¹å®¡æ ¸**
   - äº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·
   - æ‰¹é‡æ“ä½œæ”¯æŒ
   - æ‰€æœ‰å†…å®¹é»˜è®¤draftçŠ¶æ€

6. **ç»Ÿè®¡åˆ†æ**
   - å®æ—¶ç»Ÿè®¡ä¿¡æ¯
   - JSONæŠ¥å‘Šç”Ÿæˆ
   - å†…å®¹è´¨é‡åˆ†æ

7. **å®šæ—¶ä»»åŠ¡**
   - GitHub Actionsæ”¯æŒ
   - Vercel Cronæ”¯æŒ
   - å¤–éƒ¨CronæœåŠ¡æ”¯æŒ

8. **é”™è¯¯å¤„ç†**
   - è‡ªåŠ¨é‡è¯•æœºåˆ¶
   - è¯¦ç»†é”™è¯¯æ—¥å¿—
   - ç¤¼è²Œçˆ¬å–ï¼ˆè¯·æ±‚é—´éš”ï¼‰

## ğŸ“Š æ•°æ®æ¥æºé…ç½®

| æ¥æº | ç»„ç»‡ | ç­‰çº§ | é¡µé¢æ•° | çŠ¶æ€ |
|------|------|------|--------|------|
| CDC | Centers for Disease Control | A | 2 | âœ… å·²é…ç½® |
| AAP | American Academy of Pediatrics | A | 2 | âœ… å·²é…ç½® |
| Health Canada | Health Canada | A | 1 | âœ… å·²é…ç½® |
| WHO | World Health Organization | A | 1 | âœ… å·²é…ç½® |
| NIH | National Institutes of Health | A | 1 | âœ… å·²é…ç½® |
| Mayo Clinic | Mayo Clinic | A | 1 | âœ… å·²é…ç½® |

**æ€»è®¡ï¼š6ä¸ªæ¥æºï¼Œ8ä¸ªé¡µé¢**

## ğŸ”„ å·¥ä½œæµç¨‹

```
1. è§¦å‘æ–¹å¼
   â”œâ”€ æ‰‹åŠ¨è¿è¡Œ: node scripts/test-scraper-full.js
   â”œâ”€ APIè§¦å‘: POST /api/scraper/run
   â”œâ”€ GitHub Actions: æ¯å¤©è‡ªåŠ¨è¿è¡Œ
   â””â”€ å¤–éƒ¨Cron: å®šæ—¶è§¦å‘API

2. çˆ¬å–è¿‡ç¨‹
   â”œâ”€ å‘é€HTTPè¯·æ±‚
   â”œâ”€ è§£æHTMLå†…å®¹
   â”œâ”€ æå–ç»“æ„åŒ–æ•°æ®
   â”œâ”€ æ£€æŸ¥æ˜¯å¦é‡å¤ï¼ˆslugï¼‰
   â””â”€ éªŒè¯å†…å®¹è´¨é‡

3. æ•°æ®å­˜å‚¨
   â”œâ”€ ä¿å­˜åŸå§‹æ•°æ®ï¼ˆæœ¬åœ°æ–‡ä»¶ï¼‰
   â”œâ”€ åˆ›å»º/è·å–æ•°æ®æ¥æº
   â”œâ”€ æ’å…¥æ–‡ç« ï¼ˆstatus=draftï¼‰
   â””â”€ æ·»åŠ å¼•ç”¨æ¥æº

4. å†…å®¹å®¡æ ¸
   â”œâ”€ è¿è¡Œå®¡æ ¸å·¥å…·
   â”œâ”€ æŸ¥çœ‹/ç¼–è¾‘å†…å®¹
   â”œâ”€ å‘å¸ƒæˆ–åˆ é™¤
   â””â”€ æ›´æ–°çŠ¶æ€ä¸ºpublished

5. å†…å®¹å‘å¸ƒ
   â””â”€ ç½‘ç«™ä¸Šæ˜¾ç¤ºå·²å‘å¸ƒçš„æ–‡ç« 
```

## ğŸ“ ç›®å½•ç»“æ„

```
nextjs-project/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ web-scraper.js              â­ æ ¸å¿ƒå¼•æ“
â”‚   â”œâ”€â”€ scraper-config.js           â­ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ test-scraper-full.js        â­ æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ review-scraped-content.js   
â”‚   â”œâ”€â”€ scraper-stats.js            
â”‚   â””â”€â”€ cron-example.js             
â”‚
â”œâ”€â”€ src/app/api/scraper/
â”‚   â”œâ”€â”€ run/route.ts                â­ APIç«¯ç‚¹
â”‚   â””â”€â”€ status/route.ts             
â”‚
â”œâ”€â”€ data/scraped/                   ğŸ“ åŸå§‹æ•°æ®
â”œâ”€â”€ cache/scraper/                  ğŸ“ ç¼“å­˜
â”œâ”€â”€ reports/                        ğŸ“ æŠ¥å‘Š
â”‚
â””â”€â”€ æ–‡æ¡£/
    â”œâ”€â”€ SCRAPER_README.md           ğŸ“š æŠ€æœ¯æ–‡æ¡£
    â”œâ”€â”€ SCRAPER_GUIDE.md            ğŸ“š ä½¿ç”¨æŒ‡å—
    â”œâ”€â”€ SCRAPER_QUICKSTART.md       ğŸ“š å¿«é€Ÿå¼€å§‹
    â”œâ”€â”€ TEST_SCRAPER_NOW.md         ğŸ“š æµ‹è¯•è¯´æ˜
    â””â”€â”€ SCRAPER_COMPLETE.md         ğŸ“š æœ¬æ–‡æ¡£
```

## âš™ï¸ é…ç½®é€‰é¡¹

### çˆ¬å–é¢‘ç‡
ç¼–è¾‘ `scripts/scraper-config.js`:
```javascript
concurrency: {
  maxConcurrent: 2,          // å¹¶å‘æ•°
  delayBetweenRequests: 1000 // å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
}
```

### é‡è¯•æœºåˆ¶
```javascript
retryConfig: {
  maxRetries: 3,
  retryDelay: 2000,
  backoffMultiplier: 2
}
```

### æ·»åŠ æ–°æ•°æ®æº
åœ¨ `SOURCES` å¯¹è±¡ä¸­æ·»åŠ ï¼š
```javascript
MY_SOURCE: {
  id: 'my-source',
  name: 'My Health Source',
  organization: 'My Org',
  baseUrl: 'https://example.com',
  grade: 'A',
  targetPages: [...]
}
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šæ‰‹åŠ¨æµ‹è¯•
```bash
# æµ‹è¯•çˆ¬å–åŠŸèƒ½
node scripts/test-scraper-full.js

# æŸ¥çœ‹ç»“æœ
npm run scrape:stats

# å®¡æ ¸å†…å®¹
npm run scrape:review
```

### åœºæ™¯2ï¼šå®šæ—¶è‡ªåŠ¨çˆ¬å–
```yaml
# GitHub Actions æ¯å¤©è¿è¡Œ
schedule:
  - cron: '0 2 * * *'
```

### åœºæ™¯3ï¼šAPIé›†æˆ
```javascript
// åœ¨ä½ çš„åº”ç”¨ä¸­è§¦å‘çˆ¬è™«
fetch('https://yourdomain.com/api/scraper/run', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer YOUR_API_KEY'
  }
});
```

### åœºæ™¯4ï¼šPythonæ•°æ®é‡‡é›†
```bash
# ä½¿ç”¨ä½ çš„ ingest.py
cd mombaby_ingest
python ingest.py --sources pubmed,who --limit 200
```

## ğŸ” å®‰å…¨æ£€æŸ¥æ¸…å•

- [ ] `.env.local` æ–‡ä»¶å­˜åœ¨ä¸”é…ç½®æ­£ç¡®
- [ ] `.env.local` å·²æ·»åŠ åˆ° `.gitignore`
- [ ] `SCRAPER_API_KEY` ä½¿ç”¨å¼ºéšæœºå¯†é’¥
- [ ] Supabase RLSï¼ˆè¡Œçº§å®‰å…¨ï¼‰å·²é…ç½®
- [ ] APIç«¯ç‚¹ä½¿ç”¨Bearer Tokenè®¤è¯
- [ ] æ‰€æœ‰çˆ¬å–å†…å®¹é»˜è®¤ä¸ºdraftçŠ¶æ€

## ğŸ“ˆ ç›‘æ§å»ºè®®

### 1. æ—¥å¿—ç›‘æ§
```bash
# æŸ¥çœ‹çˆ¬å–æ—¥å¿—
ls -lh data/scraped/

# æŸ¥çœ‹æœ€æ–°æ•°æ®
tail -1 data/scraped/*.json | jq .
```

### 2. æ•°æ®åº“ç›‘æ§
```sql
-- æ¯æ—¥çˆ¬å–ç»Ÿè®¡
SELECT 
  DATE(created_at) as date,
  COUNT(*) as articles
FROM articles
WHERE reviewed_by = 'Web Scraper Bot'
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

### 3. è´¨é‡ç›‘æ§
```bash
# æŸ¥çœ‹ç»Ÿè®¡
npm run scrape:stats

# ç”ŸæˆæŠ¥å‘Š
npm run scrape:report
cat reports/scraper-stats.json
```

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: å¦‚ä½•é¿å…é‡å¤æ•°æ®ï¼Ÿ
A: è„šæœ¬è‡ªåŠ¨é€šè¿‡slugæ£€æŸ¥ï¼Œä¸ä¼šé‡å¤æ’å…¥ã€‚

### Q: å¯ä»¥ä¿®æ”¹çˆ¬å–é¢‘ç‡å—ï¼Ÿ
A: å¯ä»¥ï¼Œç¼–è¾‘ `.github/workflows/scraper-cron.yml` ä¸­çš„cronè¡¨è¾¾å¼ã€‚

### Q: å¦‚ä½•æ·»åŠ æ–°çš„æ•°æ®æºï¼Ÿ
A: åœ¨ `scripts/scraper-config.js` çš„ `SOURCES` å¯¹è±¡ä¸­æ·»åŠ é…ç½®ã€‚

### Q: çˆ¬å–çš„å†…å®¹éœ€è¦å®¡æ ¸å—ï¼Ÿ
A: æ˜¯çš„ï¼Œæ‰€æœ‰å†…å®¹åˆå§‹ä¸ºdraftçŠ¶æ€ï¼Œéœ€è¦è¿è¡Œ `npm run scrape:review` å®¡æ ¸ã€‚

### Q: å¯ä»¥çˆ¬å–åŠ¨æ€JavaScriptæ¸²æŸ“çš„é¡µé¢å—ï¼Ÿ
A: å¯ä»¥ï¼Œéœ€è¦ä½¿ç”¨Puppeteerï¼ˆå·²åœ¨ä¾èµ–ä¸­ï¼‰ã€‚

## ğŸ‰ ä¸‹ä¸€æ­¥

### ç«‹å³æµ‹è¯•
```bash
cd nextjs-project
npm install
node scripts/test-scraper-full.js
```

### é…ç½®Cron
1. æ¨é€ä»£ç åˆ°GitHub
2. æ·»åŠ Secretsï¼ˆAPP_URL, SCRAPER_API_KEYï¼‰
3. è‡ªåŠ¨è¿è¡Œï¼

### é›†æˆPythonè„šæœ¬
1. å°†ä½ çš„ `ingest.py` ç§»åˆ°é¡¹ç›®ä¸­
2. è®¾ç½®å•ç‹¬çš„cronä»»åŠ¡
3. åŒç³»ç»Ÿå¹¶è¡Œè¿è¡Œ

## ğŸ“š å‚è€ƒæ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹](./SCRAPER_QUICKSTART.md) - 5åˆ†é’Ÿå…¥é—¨
- [å®Œæ•´æŒ‡å—](./SCRAPER_GUIDE.md) - è¯¦ç»†æ–‡æ¡£
- [æµ‹è¯•è¯´æ˜](./TEST_SCRAPER_NOW.md) - ç«‹å³æµ‹è¯•
- [æŠ€æœ¯æ–‡æ¡£](./SCRAPER_README.md) - ç³»ç»Ÿæ¶æ„
- [Pythonå¯¹æ¯”](./SCRAPER_COMPARISON.md) - æ–¹æ¡ˆå¯¹æ¯”

---

## âœ… æ£€æŸ¥æ¸…å•

- [ ] ä¾èµ–å·²å®‰è£… (`npm install`)
- [ ] ç¯å¢ƒå˜é‡å·²é…ç½®
- [ ] æµ‹è¯•è„šæœ¬è¿è¡ŒæˆåŠŸ
- [ ] æ•°æ®æˆåŠŸå­˜å…¥Supabase
- [ ] APIæµ‹è¯•é€šè¿‡
- [ ] Cronä»»åŠ¡å·²é…ç½®
- [ ] æ–‡æ¡£å·²é˜…è¯»

---

**ğŸŠ æ­å–œï¼ä½ çš„çˆ¬è™«ç³»ç»Ÿå·²ç»å®Œå…¨å‡†å¤‡å¥½äº†ï¼**

**ç°åœ¨è¿è¡Œï¼š**
```bash
node scripts/test-scraper-full.js
```

**å¼€å§‹çˆ¬å–æ•°æ®ï¼** ğŸš€

---

**åˆ›å»ºæ—¶é—´:** 2025-01-08  
**ç³»ç»ŸçŠ¶æ€:** âœ… å®Œå…¨å°±ç»ª  
**æµ‹è¯•çŠ¶æ€:** â³ ç­‰å¾…ä½ è¿è¡Œ

