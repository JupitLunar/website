# Web Scraper ä½¿ç”¨æŒ‡å—

è¿™æ˜¯ä¸€ä¸ªä»æƒå¨å¥åº·ç½‘ç«™çˆ¬å–å†…å®¹å¹¶å­˜å‚¨åˆ°Supabaseçš„è‡ªåŠ¨åŒ–çˆ¬è™«ç³»ç»Ÿã€‚

## ğŸ“‹ ç›®å½•

- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
- [é…ç½®](#é…ç½®)
- [APIä½¿ç”¨](#apiä½¿ç”¨)
- [Cron Jobè®¾ç½®](#cron-jobè®¾ç½®)
- [æ•°æ®æ¥æº](#æ•°æ®æ¥æº)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ğŸ¯ åŠŸèƒ½ç‰¹æ€§

- âœ… ä»å¤šä¸ªæƒå¨å¥åº·ç½‘ç«™çˆ¬å–å†…å®¹ (CDC, AAP, Health Canada, WHO, NIH, Mayo Clinic)
- âœ… è‡ªåŠ¨æå–å’Œæ¸…ç†å†…å®¹
- âœ… æ™ºèƒ½æ•°æ®æ˜ å°„åˆ°Supabaseè¡¨
- âœ… APIæ¥å£æ”¯æŒcron jobå®šæœŸæ‰§è¡Œ
- âœ… é”™è¯¯é‡è¯•æœºåˆ¶
- âœ… å†…å®¹è´¨é‡éªŒè¯
- âœ… é˜²æ­¢é‡å¤å†…å®¹
- âœ… ä¿å­˜åŸå§‹æ•°æ®å¤‡ä»½

## âš™ï¸ é…ç½®

### 1. ç¯å¢ƒå˜é‡

åœ¨ `.env.local` æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹å˜é‡ï¼š

```bash
# Supabaseé…ç½®ï¼ˆå·²æœ‰ï¼‰
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# çˆ¬è™«APIå¯†é’¥ï¼ˆæ–°å¢ï¼‰
SCRAPER_API_KEY=your_secure_random_key_here
```

ç”Ÿæˆå®‰å…¨çš„APIå¯†é’¥ï¼š
```bash
# ä½¿ç”¨opensslç”Ÿæˆéšæœºå¯†é’¥
openssl rand -hex 32
```

### 2. å®‰è£…ä¾èµ–

```bash
cd nextjs-project
npm install
```

æ–°å¢çš„ä¾èµ–åŒ…ï¼š
- `axios` - HTTPè¯·æ±‚
- `cheerio` - HTMLè§£æ
- `puppeteer` - æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆå¯é€‰ï¼Œç”¨äºJavaScriptæ¸²æŸ“çš„é¡µé¢ï¼‰

### 3. è‡ªå®šä¹‰çˆ¬å–ç›®æ ‡

ç¼–è¾‘ `scripts/scraper-config.js` æ¥ï¼š
- æ·»åŠ /åˆ é™¤æ•°æ®æ¥æº
- ä¿®æ”¹CSSé€‰æ‹©å™¨
- è°ƒæ•´æ•°æ®æ¸…æ´—è§„åˆ™
- é…ç½®é‡è¯•å’Œå¹¶å‘è®¾ç½®

## ğŸš€ APIä½¿ç”¨

### è¿è¡Œçˆ¬è™«

**ç«¯ç‚¹:** `POST /api/scraper/run`

**è¯·æ±‚ç¤ºä¾‹:**

```bash
# çˆ¬å–æ‰€æœ‰é…ç½®çš„æ¥æº
curl -X POST http://localhost:3000/api/scraper/run \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json"

# åªçˆ¬å–æŒ‡å®šæ¥æº
curl -X POST http://localhost:3000/api/scraper/run \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "sources": ["CDC", "AAP"]
  }'
```

**å“åº”ç¤ºä¾‹:**

```json
{
  "success": true,
  "message": "Scraping completed",
  "data": {
    "total": 6,
    "successful": 5,
    "failed": 0,
    "skipped": 1,
    "articles": [
      {
        "id": "uuid-here",
        "title": "Infant Nutrition Guidelines",
        "source": "CDC"
      }
    ],
    "timestamp": "2025-01-08T10:30:00.000Z"
  }
}
```

### æŸ¥è¯¢é…ç½®

**ç«¯ç‚¹:** `GET /api/scraper/run`

```bash
curl http://localhost:3000/api/scraper/run \
  -H "Authorization: Bearer YOUR_API_KEY"
```

**å“åº”:**

```json
{
  "success": true,
  "message": "Scraper configuration",
  "data": {
    "sources": [
      {
        "key": "CDC",
        "name": "Centers for Disease Control and Prevention (CDC)",
        "organization": "CDC",
        "grade": "A",
        "pageCount": 2
      }
    ],
    "totalSources": 6,
    "totalPages": 8,
    "status": "ready"
  }
}
```

### æŸ¥è¯¢çŠ¶æ€

**ç«¯ç‚¹:** `GET /api/scraper/status`

```bash
curl http://localhost:3000/api/scraper/status \
  -H "Authorization: Bearer YOUR_API_KEY"
```

**å“åº”:**

```json
{
  "success": true,
  "data": {
    "recentArticles": [
      {
        "id": "uuid",
        "title": "Baby Sleep Guidelines",
        "slug": "baby-sleep-guidelines",
        "hub": "sleep",
        "created_at": "2025-01-08T10:00:00.000Z"
      }
    ],
    "recentCount": 5,
    "totalScrapedArticles": 42,
    "sources": [...],
    "timestamp": "2025-01-08T10:30:00.000Z"
  }
}
```

## â° Cron Jobè®¾ç½®

### ä½¿ç”¨Vercel Cron

åœ¨ `vercel.json` ä¸­æ·»åŠ ï¼š

```json
{
  "crons": [
    {
      "path": "/api/scraper/run",
      "schedule": "0 2 * * *"
    }
  ]
}
```

æ³¨æ„ï¼šVercelçš„cronéœ€è¦åœ¨é¡¹ç›®è®¾ç½®ä¸­é…ç½®Authorization headerã€‚

### ä½¿ç”¨å¤–éƒ¨CronæœåŠ¡

æ¨èä½¿ç”¨ä»¥ä¸‹æœåŠ¡ï¼š

1. **EasyCron** (https://www.easycron.com/)
2. **Cron-job.org** (https://cron-job.org/)
3. **GitHub Actions**

#### GitHub Actionsç¤ºä¾‹

åˆ›å»º `.github/workflows/scraper.yml`:

```yaml
name: Run Web Scraper

on:
  schedule:
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œï¼ˆUTCæ—¶é—´ï¼‰
    - cron: '0 2 * * *'
  workflow_dispatch: # å…è®¸æ‰‹åŠ¨è§¦å‘

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Run Scraper
        run: |
          curl -X POST ${{ secrets.APP_URL }}/api/scraper/run \
            -H "Authorization: Bearer ${{ secrets.SCRAPER_API_KEY }}" \
            -H "Content-Type: application/json"
```

éœ€è¦åœ¨GitHub Secretsä¸­é…ç½®ï¼š
- `APP_URL`: ä½ çš„åº”ç”¨URLï¼ˆå¦‚ https://yourdomain.comï¼‰
- `SCRAPER_API_KEY`: çˆ¬è™«APIå¯†é’¥

### ä½¿ç”¨Linux Crontab

```bash
# ç¼–è¾‘crontab
crontab -e

# æ·»åŠ ä»¥ä¸‹è¡Œï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œï¼‰
0 2 * * * curl -X POST https://yourdomain.com/api/scraper/run -H "Authorization: Bearer YOUR_API_KEY" >> /var/log/scraper.log 2>&1
```

## ğŸ“Š æ•°æ®æ¥æº

### å½“å‰é…ç½®çš„æ¥æº

| æ¥æº | ç»„ç»‡ | ç­‰çº§ | é¡µé¢æ•° |
|------|------|------|--------|
| CDC | Centers for Disease Control and Prevention | A | 2 |
| AAP | American Academy of Pediatrics | A | 2 |
| Health Canada | Health Canada | A | 1 |
| WHO | World Health Organization | A | 1 |
| NIH | National Institutes of Health | A | 1 |
| Mayo Clinic | Mayo Clinic | A | 1 |

### æ•°æ®æµç¨‹

```
æƒå¨ç½‘ç«™ â†’ çˆ¬è™« â†’ æ•°æ®æ¸…æ´— â†’ è´¨é‡éªŒè¯ â†’ Supabase
                                              â†“
                                          - kb_sources
                                          - articles (status: draft)
                                          - citations
```

æ‰€æœ‰çˆ¬å–çš„æ–‡ç« åˆå§‹çŠ¶æ€ä¸º `draft`ï¼Œéœ€è¦äººå·¥å®¡æ ¸åå†å‘å¸ƒã€‚

## ğŸ§ª æµ‹è¯•

### æœ¬åœ°æµ‹è¯•

```bash
# æµ‹è¯•æ¨¡å¼ï¼ˆåªçˆ¬å–ä¸€ä¸ªé¡µé¢ï¼‰
npm run scrape:test

# å®Œæ•´çˆ¬å–
npm run scrape

# åªçˆ¬å–ç‰¹å®šæ¥æº
node scripts/web-scraper.js --sources CDC,AAP
```

### APIæµ‹è¯•

```bash
# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•API
curl -X POST http://localhost:3000/api/scraper/run \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json"
```

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜: 401 Unauthorized

**åŸå› :** APIå¯†é’¥é”™è¯¯æˆ–æœªé…ç½®

**è§£å†³æ–¹æ¡ˆ:**
1. æ£€æŸ¥ `.env.local` ä¸­çš„ `SCRAPER_API_KEY`
2. ç¡®ä¿è¯·æ±‚å¤´æ­£ç¡®ï¼š`Authorization: Bearer YOUR_KEY`

### é—®é¢˜: å†…å®¹æå–å¤±è´¥

**åŸå› :** ç½‘ç«™æ›´æ–°äº†HTMLç»“æ„

**è§£å†³æ–¹æ¡ˆ:**
1. è¿è¡Œæµ‹è¯•æ¨¡å¼æŸ¥çœ‹åŸå§‹HTMLï¼š`npm run scrape:test`
2. æ›´æ–° `scripts/scraper-config.js` ä¸­çš„CSSé€‰æ‹©å™¨
3. æ£€æŸ¥ `data/scraped/` ç›®å½•ä¸­ä¿å­˜çš„åŸå§‹æ•°æ®

### é—®é¢˜: è¶…æ—¶é”™è¯¯

**åŸå› :** ç½‘ç»œæ…¢æˆ–ç›®æ ‡ç½‘ç«™å“åº”æ…¢

**è§£å†³æ–¹æ¡ˆ:**
1. å¢åŠ  `SCRAPER_CONFIG.requestConfig.timeout`
2. è°ƒæ•´ `retryConfig.maxRetries`

### é—®é¢˜: é‡å¤å†…å®¹

**åŸå› :** slugå†²çª

**è§£å†³æ–¹æ¡ˆ:**
- çˆ¬è™«ä¼šè‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„slug
- æ£€æŸ¥æ•°æ®åº“ä¸­ `articles` è¡¨çš„ `slug` å­—æ®µ

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç¤¼è²Œçˆ¬å–

- âœ… è®¾ç½®åˆç†çš„è¯·æ±‚é—´éš”ï¼ˆé»˜è®¤1ç§’ï¼‰
- âœ… ä½¿ç”¨æœ‰æ„ä¹‰çš„User-Agent
- âœ… éµå®ˆrobots.txt
- âœ… ä¸è¦å¹¶å‘è¿‡å¤šè¯·æ±‚ï¼ˆé»˜è®¤æœ€å¤š2ä¸ªï¼‰

### 2. æ•°æ®è´¨é‡

- âœ… æ‰€æœ‰æ–‡ç« åˆå§‹ä¸ºdraftçŠ¶æ€
- âœ… äººå·¥å®¡æ ¸åå†å‘å¸ƒ
- âœ… å®šæœŸæ£€æŸ¥çˆ¬å–çš„å†…å®¹è´¨é‡
- âœ… æ›´æ–°è¿‡æœŸçš„å†…å®¹

### 3. ç›‘æ§

- âœ… æŸ¥çœ‹çˆ¬å–æ—¥å¿—
- âœ… ç›‘æ§æˆåŠŸç‡
- âœ… è®¾ç½®å¤±è´¥é€šçŸ¥

### 4. ç»´æŠ¤

- âœ… å®šæœŸæ›´æ–°CSSé€‰æ‹©å™¨
- âœ… æ·»åŠ æ–°çš„æƒå¨æ¥æº
- âœ… æ¸…ç†æ—§çš„ç¼“å­˜æ–‡ä»¶

## ğŸ“‚ æ–‡ä»¶ç»“æ„

```
nextjs-project/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper-config.js    # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ web-scraper.js        # æ ¸å¿ƒçˆ¬è™«é€»è¾‘
â”œâ”€â”€ src/
â”‚   â””â”€â”€ app/
â”‚       â””â”€â”€ api/
â”‚           â””â”€â”€ scraper/
â”‚               â”œâ”€â”€ run/
â”‚               â”‚   â””â”€â”€ route.ts    # è¿è¡Œçˆ¬è™«API
â”‚               â””â”€â”€ status/
â”‚                   â””â”€â”€ route.ts    # çŠ¶æ€æŸ¥è¯¢API
â”œâ”€â”€ data/
â”‚   â””â”€â”€ scraped/              # ä¿å­˜çš„åŸå§‹æ•°æ®
â””â”€â”€ cache/
    â””â”€â”€ scraper/              # ç¼“å­˜ï¼ˆå¯é€‰ï¼‰
```

## ğŸ” å®‰å…¨å»ºè®®

1. **ä¿æŠ¤APIå¯†é’¥**
   - ä¸è¦æäº¤åˆ°Git
   - ä½¿ç”¨å¼ºéšæœºå¯†é’¥
   - å®šæœŸè½®æ¢å¯†é’¥

2. **é™åˆ¶è®¿é—®**
   - åªåœ¨æœåŠ¡å™¨ç«¯è°ƒç”¨API
   - è€ƒè™‘æ·»åŠ IPç™½åå•
   - è®°å½•æ‰€æœ‰APIè°ƒç”¨

3. **æ•°æ®éªŒè¯**
   - æ‰€æœ‰çˆ¬å–å†…å®¹é»˜è®¤ä¸ºdraft
   - äººå·¥å®¡æ ¸åå†å‘å¸ƒ
   - éªŒè¯æ¥æºå¯ä¿¡åº¦

## ğŸ†˜ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
1. æ—¥å¿—æ–‡ä»¶ï¼š`/var/log/scraper.log`
2. Supabaseæ§åˆ¶å°
3. åŸå§‹æ•°æ®ï¼š`data/scraped/`

## ğŸ“„ è®¸å¯è¯

éµå®ˆå„æ•°æ®æ¥æºçš„ä½¿ç”¨æ¡æ¬¾å’Œè®¸å¯è¯ã€‚

---

**åˆ›å»ºæ—¶é—´**: 2025-01-08
**æœ€åæ›´æ–°**: 2025-01-08

