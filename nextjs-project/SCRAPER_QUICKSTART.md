# Web Scraper å¿«é€Ÿå¼€å§‹ ğŸš€

5åˆ†é’Ÿå¿«é€Ÿè®¾ç½®å’Œä½¿ç”¨çˆ¬è™«ç³»ç»Ÿã€‚

## ğŸ“¦ ç¬¬ä¸€æ­¥ï¼šå®‰è£…ä¾èµ–

```bash
cd nextjs-project
npm install
```

æ–°å¢çš„åŒ…ä¼šè‡ªåŠ¨å®‰è£…ï¼š
- `axios` - HTTPè¯·æ±‚
- `cheerio` - HTMLè§£æ  
- `puppeteer` - æµè§ˆå™¨è‡ªåŠ¨åŒ–

## ğŸ”‘ ç¬¬äºŒæ­¥ï¼šé…ç½®ç¯å¢ƒå˜é‡

### 1. ç”ŸæˆAPIå¯†é’¥

```bash
# ç”Ÿæˆå®‰å…¨çš„éšæœºå¯†é’¥
openssl rand -hex 32
```

### 2. åˆ›å»º `.env.local` æ–‡ä»¶

```bash
cp .env.example .env.local
```

### 3. ç¼–è¾‘ `.env.local`

```bash
# Supabaseé…ç½®ï¼ˆå·²æœ‰çš„ï¼‰
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# çˆ¬è™«APIå¯†é’¥ï¼ˆæ–°å¢ï¼‰
SCRAPER_API_KEY=åˆšæ‰ç”Ÿæˆçš„å¯†é’¥
```

## ğŸ§ª ç¬¬ä¸‰æ­¥ï¼šæµ‹è¯•çˆ¬è™«

### æœ¬åœ°æµ‹è¯•ï¼ˆå‘½ä»¤è¡Œï¼‰

```bash
# æµ‹è¯•æ¨¡å¼ - åªçˆ¬å–ä¸€ä¸ªé¡µé¢
npm run scrape:test

# å®Œæ•´çˆ¬å–æ‰€æœ‰é…ç½®çš„æ¥æº
npm run scrape

# åªçˆ¬å–ç‰¹å®šæ¥æº
node scripts/web-scraper.js --sources CDC,AAP
```

### APIæµ‹è¯•

```bash
# 1. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev

# 2. åœ¨å¦ä¸€ä¸ªç»ˆç«¯æµ‹è¯•API
curl -X POST http://localhost:3000/api/scraper/run \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json"
```

## ğŸŒ ç¬¬å››æ­¥ï¼šè®¾ç½®Cron Job

é€‰æ‹©ä»¥ä¸‹ä»»ä¸€æ–¹å¼ï¼š

### æ–¹å¼1ï¼šGitHub Actionsï¼ˆæ¨èï¼‰

**ä¼˜ç‚¹ï¼š** å…è´¹ã€å¯é ã€æœ‰æ—¥å¿—

1. åœ¨GitHubä»“åº“ä¸­æ·»åŠ Secretsï¼š
   - `APP_URL`: `https://yourdomain.com`
   - `SCRAPER_API_KEY`: ä½ çš„APIå¯†é’¥

2. æ¨é€ä»£ç ï¼ˆ`.github/workflows/scraper-cron.yml` å·²åˆ›å»ºï¼‰

3. å®Œæˆï¼æ¯å¤©è‡ªåŠ¨è¿è¡Œ

### æ–¹å¼2ï¼šVercel Cron

**ä¼˜ç‚¹ï¼š** ä¸éƒ¨ç½²é›†æˆ

åœ¨ `vercel.json` ä¸­æ·»åŠ ï¼š

```json
{
  "crons": [
    {
      "path": "/api/scraper/run",
      "schedule": "0 2 * * *"
    }
  ]
}
```

ç„¶ååœ¨Vercelé¡¹ç›®è®¾ç½®ä¸­é…ç½®ç¯å¢ƒå˜é‡ `SCRAPER_API_KEY`ã€‚

### æ–¹å¼3ï¼šå¤–éƒ¨CronæœåŠ¡

**æ¨èæœåŠ¡ï¼š**
- [EasyCron](https://www.easycron.com/)
- [Cron-job.org](https://cron-job.org/)

**é…ç½®ï¼š**
- URL: `https://yourdomain.com/api/scraper/run`
- Method: POST
- Header: `Authorization: Bearer YOUR_API_KEY`
- Schedule: `0 2 * * *` (æ¯å¤©å‡Œæ™¨2ç‚¹)

### æ–¹å¼4ï¼šNode.js CronæœåŠ¡å™¨

ä½¿ç”¨æä¾›çš„ç¤ºä¾‹è„šæœ¬ï¼š

```bash
node scripts/cron-example.js
```

é…åˆ `node-cron` æˆ– `pm2` ä½¿ç”¨ã€‚

## ğŸ“Š ç¬¬äº”æ­¥ï¼šæŸ¥çœ‹ç»“æœ

### 1. é€šè¿‡APIæŸ¥è¯¢

```bash
# æŸ¥è¯¢æœ€è¿‘çš„çˆ¬å–çŠ¶æ€
curl http://localhost:3000/api/scraper/status \
  -H "Authorization: Bearer YOUR_API_KEY"
```

### 2. Supabaseæ§åˆ¶å°

ç™»å½• [Supabase Dashboard](https://app.supabase.com)ï¼ŒæŸ¥çœ‹ï¼š

- `kb_sources` è¡¨ - æ•°æ®æ¥æº
- `articles` è¡¨ - çˆ¬å–çš„æ–‡ç« ï¼ˆstatus='draft'ï¼‰
- `citations` è¡¨ - å¼•ç”¨æ¥æº

### 3. æœ¬åœ°æ–‡ä»¶

çˆ¬å–çš„åŸå§‹æ•°æ®ä¿å­˜åœ¨ï¼š
```
nextjs-project/data/scraped/
```

## ğŸ¯ å¸¸ç”¨å‘½ä»¤

```bash
# æœ¬åœ°æµ‹è¯•
npm run scrape:test              # æµ‹è¯•å•ä¸ªé¡µé¢
npm run scrape                   # å®Œæ•´çˆ¬å–

# APIæµ‹è¯•
npm run dev                      # å¯åŠ¨å¼€å‘æœåŠ¡å™¨
chmod +x scripts/test-scraper-api.sh
./scripts/test-scraper-api.sh   # æµ‹è¯•APIï¼ˆéœ€è¦jqï¼‰

# æŸ¥çœ‹æ—¥å¿—
tail -f data/scraped/*.json     # æŸ¥çœ‹çˆ¬å–çš„åŸå§‹æ•°æ®
```

## âš™ï¸ è‡ªå®šä¹‰é…ç½®

ç¼–è¾‘ `scripts/scraper-config.js` æ¥è‡ªå®šä¹‰ï¼š

### æ·»åŠ æ–°çš„æ•°æ®æ¥æº

```javascript
MY_SOURCE: {
  id: 'my-source',
  name: 'My Health Source',
  organization: 'My Org',
  baseUrl: 'https://example.com',
  grade: 'A',
  targetPages: [
    {
      url: 'https://example.com/article',
      type: 'nutrition',
      category: 'feeding',
      selectors: {
        title: 'h1.title',
        content: '.main-content',
        paragraphs: '.main-content p',
        lists: '.main-content ul, .main-content ol'
      }
    }
  ]
}
```

### è°ƒæ•´çˆ¬å–é¢‘ç‡

```javascript
concurrency: {
  maxConcurrent: 2,          // å¹¶å‘è¯·æ±‚æ•°
  delayBetweenRequests: 1000 // è¯·æ±‚é—´éš”(æ¯«ç§’)
}
```

## ğŸ” æ‰¾åˆ°æ­£ç¡®çš„CSSé€‰æ‹©å™¨

### æ–¹æ³•1ï¼šæµè§ˆå™¨å¼€å‘å·¥å…·

1. åœ¨ç›®æ ‡ç½‘ç«™å³é”® â†’ "æ£€æŸ¥å…ƒç´ "
2. æ‰¾åˆ°å†…å®¹å…ƒç´ 
3. å³é”® â†’ Copy â†’ Copy selector

### æ–¹æ³•2ï¼šä½¿ç”¨æµ‹è¯•æ¨¡å¼

```bash
npm run scrape:test
```

æŸ¥çœ‹ `data/scraped/` ä¸­ä¿å­˜çš„HTMLï¼Œåˆ†æç»“æ„ã€‚

## ğŸ“‹ Cronè¡¨è¾¾å¼è¯´æ˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ åˆ†é’Ÿ (0-59)
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å°æ—¶ (0-23)
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ—¥æœŸ (1-31)
â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æœˆä»½ (1-12)
â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ˜ŸæœŸ (0-6) (å‘¨æ—¥=0)
â”‚ â”‚ â”‚ â”‚ â”‚
* * * * *
```

å¸¸ç”¨ç¤ºä¾‹ï¼š
- `0 2 * * *` - æ¯å¤©å‡Œæ™¨2ç‚¹
- `0 */6 * * *` - æ¯6å°æ—¶
- `0 2 * * 1` - æ¯å‘¨ä¸€å‡Œæ™¨2ç‚¹
- `0 2 1 * *` - æ¯æœˆ1å·å‡Œæ™¨2ç‚¹

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: çˆ¬å–å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®
2. CSSé€‰æ‹©å™¨æ˜¯å¦æ­£ç¡®
3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸
4. æŸ¥çœ‹é”™è¯¯æ—¥å¿—

### Q: å¦‚ä½•é˜²æ­¢é‡å¤å†…å®¹ï¼Ÿ

A: çˆ¬è™«ä¼šè‡ªåŠ¨æ£€æŸ¥slugï¼Œè·³è¿‡å·²å­˜åœ¨çš„å†…å®¹ã€‚

### Q: çˆ¬å–çš„å†…å®¹éœ€è¦å®¡æ ¸å—ï¼Ÿ

A: æ˜¯çš„ï¼Œæ‰€æœ‰å†…å®¹åˆå§‹çŠ¶æ€ä¸º `draft`ï¼Œéœ€è¦äººå·¥å®¡æ ¸åè®¾ç½®ä¸º `published`ã€‚

### Q: å¦‚ä½•æ›´æ–°ç¯å¢ƒå˜é‡ï¼Ÿ

A: 
- æœ¬åœ°ï¼šç¼–è¾‘ `.env.local`
- Vercelï¼šåœ¨é¡¹ç›®è®¾ç½®ä¸­æ›´æ–°
- GitHub Actionsï¼šåœ¨ä»“åº“Secretsä¸­æ›´æ–°

## ğŸ“š å®Œæ•´æ–‡æ¡£

æŸ¥çœ‹ [SCRAPER_GUIDE.md](./SCRAPER_GUIDE.md) è·å–è¯¦ç»†æ–‡æ¡£ã€‚

## âœ… æ£€æŸ¥æ¸…å•

- [ ] å®‰è£…ä¾èµ– (`npm install`)
- [ ] é…ç½®ç¯å¢ƒå˜é‡ (`.env.local`)
- [ ] æœ¬åœ°æµ‹è¯•é€šè¿‡ (`npm run scrape:test`)
- [ ] APIæµ‹è¯•é€šè¿‡
- [ ] è®¾ç½®Cron Job
- [ ] é…ç½®é€šçŸ¥ï¼ˆå¯é€‰ï¼‰
- [ ] æ–‡æ¡£é˜…è¯»å®Œæˆ

---

**å¼€å§‹æ—¶é—´ï¼š5åˆ†é’Ÿ**  
**ç°åœ¨å¼€å§‹çˆ¬å–ï¼** ğŸ‰

